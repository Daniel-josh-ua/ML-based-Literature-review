{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Master_Thesis_Text_Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb0-9gHyTjYC"
      },
      "source": [
        "**Installing the Dependencies:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cKKhzO8Pn_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719af64d-93ac-4d4f-fa40-c7f05db63b8c"
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 221kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/bb/abde8f73a4a8652b80944fae0838adb967e5c47e70f9f3f5cdc56422df39/spacy_legacy-3.0.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/ae/ecfa3e2dc267010fa320034be0eb3a8e683dc98dae7e70f92b41605b4d35/pathy-0.6.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 30.4MB/s \n",
            "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6e/bd2da3d71ab2d175248949ac106fee09ae13bfaca39002eabdbd908b7440/thinc-8.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (619kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Installing collected packages: spacy-legacy, typer, pathy, catalogue, srsly, pydantic, thinc, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.6.0 pydantic-1.7.4 spacy-3.0.6 spacy-legacy-3.0.7 srsly-2.4.1 thinc-8.0.7 typer-0.3.2\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 115kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQEFWFP4RmzK",
        "outputId": "98a2281e-e6e2-4789-9aa9-373e4642829b"
      },
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 09:23:53.421699: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 239kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.7)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.0.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.1.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.3.1\n",
            "    Uninstalling en-core-web-sm-2.3.1:\n",
            "      Successfully uninstalled en-core-web-sm-2.3.1\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "ZriLKqi0RFAW",
        "outputId": "a8657f32-7d19-4e30-839e-33d66ba0fe2a"
      },
      "source": [
        "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz --no-deps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1MB 6.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-cp37-none-any.whl size=12047105 sha256=16da6f75bfdfbf3c9cb47b0dabd874b9d97e6070792010f32de91cc8bfde0a07\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/3f/41/f0b92863355c3ba34bb32b37d8a0c662959da0058202094f46\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "en_core_web_sm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbkLhXN5Tqga"
      },
      "source": [
        "**Importing and loading the features:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzE9xnqbAX76"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5pnM2sHc04"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMI-KlIHmJS"
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAxyzDn04L-n",
        "outputId": "d808c742-fea2-4637-9ce8-9821e418877c"
      },
      "source": [
        "print(STOP_WORDS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'became', 'the', 'in', 'upon', 'may', 'eight', 'to', 'something', 'become', 'ever', 'hence', 'ourselves', 'call', 'thence', 'itself', 'somewhere', 'these', 'whoever', 'whereupon', 'move', 'therein', 'we', 'done', 'his', 'same', 'whence', 'by', 'empty', 'toward', 'she', 'mine', 'amount', 'what', 'herself', 'take', 'least', 're', 'well', 'yet', 'make', 'himself', 'if', 'towards', 'here', 'anyone', 'why', 'six', 'thus', 'when', 'whom', 'each', '’ve', 'unless', \"'s\", 'next', 'all', 'down', 'have', 'every', 'be', 'some', 'yourself', '’m', 'after', 'someone', 'only', 'show', 'over', 'seems', 'none', 'my', 'along', 'first', 'into', 'much', 'beforehand', 'up', 'please', 'it', 'yourselves', 'amongst', 'below', 'with', 'where', 'such', 'elsewhere', 'behind', 'you', 'so', 'those', 'see', 'however', 'moreover', 'again', 'among', 'bottom', 'between', 'us', 'were', 'give', 'beyond', '‘s', 'their', \"'re\", 'did', 'per', 'nowhere', 'now', 'still', 'ten', '’ll', 'except', 'thereby', 'n’t', 'everything', 'therefore', 'go', 'around', 'than', 'any', 'had', 'but', 'noone', 'though', 'are', 'twenty', 'latterly', 'third', 'nevertheless', 'no', 'would', 'or', 'myself', \"'d\", \"n't\", 'he', 'less', 'keep', 'once', 'whose', 'forty', 'almost', 'do', 'others', 'our', 'eleven', 'two', 'how', 'anyway', 'out', 'against', 'then', 'twelve', 'name', 'herein', 'while', 'either', 'seemed', 'wherein', 'nothing', 'another', \"'m\", 'during', 'ca', 'one', 'whereas', '’d', 'i', 'whether', 'thereafter', 'within', 'everyone', 'used', 'regarding', 'from', '‘ll', 'anyhow', 'also', 'there', 'former', 'quite', 'must', 'whole', 'not', 'am', 'which', 'nor', 'somehow', 'besides', 'hereafter', 'last', 'three', 'seem', 'could', 'five', 'never', 'latter', 'a', 'just', 'does', 'as', 'perhaps', 'own', 'about', 'whereby', 'seeming', 'they', 'very', 'n‘t', 'whatever', 'enough', \"'ll\", 'until', 'indeed', 'already', 'fifty', 'even', 'without', 'meanwhile', 'whither', 'will', 'get', 'who', 'its', 'hers', 'part', 'off', 'ours', 'an', 'hundred', 'throughout', 'full', 'put', 'cannot', \"'ve\", 'afterwards', '‘ve', 'back', 'mostly', 'this', 'her', 'me', 'beside', 'themselves', 'using', 'everywhere', 'else', 'thereupon', 'whenever', 'under', 'although', '’re', 'being', 'onto', 'can', 'hereupon', 'and', 'further', 'at', 'more', '‘m', 'because', 'that', 'yours', 'nobody', 'together', 'formerly', 'made', 'on', 'really', 'sometimes', 'fifteen', '‘d', 'wherever', 'neither', 'becomes', 'otherwise', 'doing', 'been', 'say', 'too', 'has', 'several', 'many', 'hereby', 'most', 'due', 'both', 'whereafter', '‘re', 'various', 'namely', 'them', 'might', 'should', 'of', 'nine', 'via', 'other', '’s', 'for', 'front', 'anywhere', 'anything', 'through', 'serious', 'was', 'often', 'rather', 'thru', 'across', 'before', 'alone', 'always', 'becoming', 'sixty', 'few', 'your', 'him', 'side', 'is', 'sometime', 'top', 'above', 'four', 'since'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKhnqL9tPFKz",
        "outputId": "c6173d2a-82fc-4434-fb67-339e7aef9e8e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqfl14d_H1oL"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHYJ8ijJJK0x",
        "outputId": "c0b7ce67-0d89-417f-87a2-da02716dd231"
      },
      "source": [
        "pip install tika"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tika\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32894 sha256=4fa807eb0bb3ccce619f4f00d1e9c8134c02d89e3218e351882fcf5e387f7168\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-1.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Wl01eJI8-Q"
      },
      "source": [
        "import os\n",
        "from tika import parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrsNm-RIUnhH"
      },
      "source": [
        "**Generating corpus from the directory of pdf files:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGm19pdmHNwU",
        "outputId": "83d66ff0-d3e0-45b1-ab00-c7a1d8eb2ed3"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Agumented_reality_corpus\" # path directory\n",
        "directory=os.path.join(path)\n",
        "pdf_text = ''\n",
        "for r,d,f in os.walk(directory): #going through subdirectories\n",
        "    for file in f:\n",
        "        if \".pdf\" in file:  # reading only PDF files\n",
        "            file_join = os.path.join(r, file)   #getting full path \n",
        "            file_data = parser.from_file(file_join)     # parsing the PDF file \n",
        "            print(file_join)\n",
        "            pdf_text = pdf_text + ' ' + file_data['content'].strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-07 09:25:29,555 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar to /tmp/tika-server.jar.\n",
            "2021-07-07 09:25:30,979 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "2021-07-07 09:25:31,425 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Agumented_reality_corpus/Industry.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/User1.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/Industry3.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/employee3.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/industry1.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/employee.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/user.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/Industry2.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/Employee2.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/cost.pdf\n",
            "/content/drive/MyDrive/Agumented_reality_corpus/User2.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5lx3yJWJRXi",
        "outputId": "f839ff8f-72bd-4aa5-ef51-55cabdc09be6"
      },
      "source": [
        "len(pdf_text)\n",
        "#looking at the number of words in the Document"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "577553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFJihcmFBaI5"
      },
      "source": [
        "doc=nlp(pdf_text)\n",
        "#running NLP function into the pdf file and naming it DOC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ_pBM8NBrce"
      },
      "source": [
        "pdf_corpus = [sent.text.lower() for sent in doc.sents ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ehcc6vLln7"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yd0R6PWU0t8"
      },
      "source": [
        "**Prepocessing the corpus for further analysis:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSZx83SQLRXi"
      },
      "source": [
        "def clean_text(text): \n",
        "    # Remove punctuation \n",
        "    punct = string.punctuation\n",
        "    #punct = punct.replace('-','')\n",
        "    delete_dict = {sp_character: '' for sp_character in punct} \n",
        "    delete_dict[' '] = ' ' \n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    # Remove white spaces\n",
        "    textArr= text1.split() \n",
        "    # Remove words containing numbers\n",
        "    text2 = [w for w in textArr if not any(n.isdigit() for n in w)]\n",
        "    # Remove words with length < 3 and numbers \n",
        "    text3 = ' '.join([w for w in text2 if ( not w.isdigit() and ( not w.isdigit() and len(w)>3))])\n",
        "    # Converting into Lowercase\n",
        "    return text3.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmOHhUaXLWAI"
      },
      "source": [
        "corpus = list(map(clean_text, pdf_corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-LRA16NJ9YK"
      },
      "source": [
        "special_words = ['Virtual','Reality','analysis','however','also','since','various','normal','crossref','arxiv','therefore','another','whether','may',\"’\",'author','study','observe','find','scrip','journal','manuscript','review','figure','result','suggest','http','elsevier','com']\n",
        "STOP_WORDS.update(special_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf62BkUcVYvH"
      },
      "source": [
        "**Vectorizing the text and generating the word frequencies:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbdOBlvgD304"
      },
      "source": [
        "cv = CountVectorizer(stop_words=list(STOP_WORDS))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQmTYR2WGJwc",
        "outputId": "6fd7efa7-bdf6-47c4-d81c-6e30bab5959d"
      },
      "source": [
        "print(cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(stop_words=['became', 'the', 'in', 'upon', 'may', 'eight', 'to',\n",
            "                            'something', 'scrip', 'become', 'ever', 'hence',\n",
            "                            'ourselves', 'call', 'thence', 'itself',\n",
            "                            'somewhere', 'these', 'whoever', 'crossref',\n",
            "                            'whereupon', 'move', 'therein', 'we', 'done', 'his',\n",
            "                            'same', 'whence', 'by', 'empty', ...])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn1vjNWwD53n",
        "outputId": "cf55e90b-bb66-4bd9-82e0-3267fd53213a"
      },
      "source": [
        "cv_fit=cv.fit_transform(corpus)\n",
        "word_list = cv.get_feature_names();    \n",
        "count_list = cv_fit.toarray().sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 'reality', 've', 'virtual'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BziJqwLMD8Sw"
      },
      "source": [
        "word_frequency = dict(zip(word_list,count_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00lbaTwgIfN3",
        "outputId": "5042f9e4-7e00-48f7-8271-6563b75f9a1a"
      },
      "source": [
        "print(cv_fit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (1, 5376)\t1\n",
            "  (1, 3006)\t1\n",
            "  (1, 3298)\t1\n",
            "  (1, 6355)\t1\n",
            "  (1, 6928)\t1\n",
            "  (1, 1766)\t1\n",
            "  (1, 471)\t1\n",
            "  (1, 5172)\t1\n",
            "  (1, 6223)\t1\n",
            "  (1, 2727)\t1\n",
            "  (1, 6990)\t1\n",
            "  (1, 4914)\t1\n",
            "  (1, 1247)\t1\n",
            "  (1, 5609)\t1\n",
            "  (1, 488)\t1\n",
            "  (2, 5051)\t1\n",
            "  (3, 4399)\t1\n",
            "  (3, 31)\t1\n",
            "  (3, 387)\t1\n",
            "  (3, 818)\t1\n",
            "  (3, 3649)\t1\n",
            "  (5, 6355)\t2\n",
            "  (5, 4591)\t1\n",
            "  (5, 5410)\t1\n",
            "  (5, 5614)\t1\n",
            "  :\t:\n",
            "  (6513, 6348)\t1\n",
            "  (6513, 5419)\t1\n",
            "  (6513, 1360)\t1\n",
            "  (6513, 4949)\t1\n",
            "  (6513, 4849)\t1\n",
            "  (6514, 980)\t1\n",
            "  (6514, 2053)\t1\n",
            "  (6514, 3811)\t1\n",
            "  (6514, 5406)\t1\n",
            "  (6515, 5376)\t1\n",
            "  (6515, 3301)\t1\n",
            "  (6515, 6407)\t1\n",
            "  (6515, 1273)\t1\n",
            "  (6515, 5255)\t1\n",
            "  (6515, 1843)\t1\n",
            "  (6515, 741)\t2\n",
            "  (6515, 2596)\t2\n",
            "  (6515, 5295)\t1\n",
            "  (6515, 3675)\t1\n",
            "  (6515, 5406)\t1\n",
            "  (6515, 3096)\t1\n",
            "  (6515, 1409)\t1\n",
            "  (6515, 3798)\t1\n",
            "  (6515, 314)\t1\n",
            "  (6515, 453)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3K_Ivb_EGAQ"
      },
      "source": [
        "val=sorted(word_frequency.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZN9QFksMeQk"
      },
      "source": [
        "higher_word_frequencies = [word for word,freq in word_frequency.items() if freq in val[-3:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqcE4kLlMfI4",
        "outputId": "50f37b05-bb96-43c1-f608-a4455fdf0ba5"
      },
      "source": [
        "print(\"\\nWords with higher frequencies: \", higher_word_frequencies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Words with higher frequencies:  ['mobile', 'reality', 'system']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JHkJ1DcMjMU"
      },
      "source": [
        "higher_frequency = val[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCIPLwZdMq_h"
      },
      "source": [
        "for word in word_frequency.keys():  \n",
        "    word_frequency[word] = (word_frequency[word]/higher_frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Zk4J4vVN5c"
      },
      "source": [
        "**Ranking the Sentence and generating the summary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqgC-TNtMxsk"
      },
      "source": [
        "sentence_rank={}\n",
        "for sent in doc.sents:\n",
        "    for word in sent :       \n",
        "        if word.text.lower() in word_frequency.keys():            \n",
        "            if sent in sentence_rank.keys():\n",
        "                sentence_rank[sent]+=word_frequency[word.text.lower()]\n",
        "            else:\n",
        "                sentence_rank[sent]=word_frequency[word.text.lower()]\n",
        "top_sentences=(sorted(sentence_rank.values())[::-1])\n",
        "top_sent=top_sentences[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaqseRpfM3AG",
        "outputId": "4a4399f3-ef28-44e9-ce52-cbcea93845e2"
      },
      "source": [
        "summary=[]\n",
        "for sent,strength in sentence_rank.items():  \n",
        "    if strength in top_sent:\n",
        "        summary.append(sent)\n",
        "    else:\n",
        "        continue\n",
        "for i in summary:\n",
        "    print(i,end=\"\\n \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Augmented reality technology \n",
            "\n",
            "Augmented reality with reality technology, interactive technology, sensor technology and computer graphics \n",
            "computer generated virtual environment and users around the reality of the environment be in harmony are an \n",
            "organic whole, the user from the sensory effects that virtual environment is part of its real surroundings7.\n",
            " From the perspective of the development of domestic augmented reality at present, although the relative to \n",
            "foreign late start, but focus on the system application technology, scope and research points are single, but a lot of \n",
            "research institutions, colleges and universities, especially in augmented reality some algorithms and design \n",
            "technology has larger, such as camera calibration algorithm as well as the virtual object registration algorithm and so \n",
            "on, the success of these algorithms research can help solve the problem of shade in the augmented reality, display \n",
            "design, etc.\n",
            " Research on human computer interaction technology system in power grid operation environment \n",
            "\n",
            "Research system of human-computer interaction technology, model design analysis of different levels, from \n",
            "cognitive science, human-computer interaction model of analysis of how users interact with the computer, the \n",
            "behavior model of another kind from the Angle of the system design to understand users, analyzing the \n",
            "characteristics of the different users in order to improve the pertinence and adaptability of the system design, namely \n",
            "the user characteristic model, a class from the structure of the system, discuss the interface in the system status and \n",
            "decomposition, namely interface structure model;\n",
            " "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "Fjtm9z23Vja8",
        "outputId": "089357d4-5a70-450c-b340-c2bfa2295ec4"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
        "from colab_pdf import colab_pdf\n",
        "colab_pdf('Master_Thesis_Text_Summarization.ipynb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-07 09:40:51--  https://raw.githubusercontent.com/brpy/colab-pdf/master/colab_pdf.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864 (1.8K) [text/plain]\n",
            "Saving to: ‘colab_pdf.py’\n",
            "\n",
            "colab_pdf.py        100%[===================>]   1.82K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-07 09:40:51 (20.4 MB/s) - ‘colab_pdf.py’ saved [1864/1864]\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Extracting templates from packages: 100%\n",
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/Master_Thesis_Text_Summarization.ipynb to pdf\n",
            "/usr/local/lib/python2.7/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) [u'application/vnd.colab-display-data+json'] is not able to be represented.\n",
            "  mimetypes=output.keys())\n",
            "[NbConvertApp] Writing 63689 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: [u'bibtex', u'./notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 51631 bytes to /content/drive/My Drive/Master_Thesis_Text_Summarization.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bb62085a-0218-4d0a-874f-4454afa7ea37\", \"Master_Thesis_Text_Summarization.pdf\", 51631)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File ready to be Downloaded and Saved to Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}